{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".dropbox already exists in df\n",
      "Picapture_16_03_2018-10:53:00.jpg already exists in df\n",
      "Picapture_16_03_2018-15:53:00.jpg already exists in df\n",
      "Picapture_16_03_2018-12:38:00.jpg already exists in df\n",
      "Picapture_16_03_2018-07:23:00.jpg already exists in df\n",
      "Picapture_16_03_2018-19:15:00.jpg already exists in df\n",
      "Picapture_16_03_2018-11:39:00.jpg already exists in df\n",
      "Picapture_16_03_2018-19:07:00.jpg already exists in df\n",
      "Picapture_16_03_2018-13:41:00.jpg already exists in df\n",
      "('junk', 0.98714221)\n",
      "('car3', 0.41164544)\n",
      "('bus', 0.90706146)\n",
      "('car3', 0.62779009)\n",
      "('largecar', 0.55781353)\n",
      "('largecar', 0.70461243)\n",
      "('fedex', 0.40971139)\n",
      "('fedex', 0.93857765)\n",
      "('largecar', 0.58967847)\n",
      "('largecar', 0.57517797)\n",
      "('largecar', 0.65228581)\n",
      "('fedex', 0.42095387)\n",
      "('largecar', 0.43728173)\n",
      "('largecar', 0.46070051)\n",
      "('largecar', 0.46776533)\n",
      "('largecar', 0.44366911)\n",
      "('car', 0.36303452)\n",
      "('largecar', 0.37718731)\n",
      "('car3', 0.34987226)\n",
      "('largecar', 0.40731394)\n",
      "('bus', 0.61233735)\n",
      "('largecar', 0.73813957)\n",
      "('largecar', 0.34337628)\n",
      "('car3', 0.4202061)\n",
      "('largecar', 0.36370164)\n",
      "('largecar', 0.62257689)\n",
      "('fedex', 0.28733668)\n",
      "('fedex', 0.8900395)\n",
      "('largecar', 0.49200267)\n",
      "('largecar', 0.70082098)\n",
      "('largecar', 0.44915363)\n",
      "('largecar', 0.51612073)\n",
      "('fedex', 0.28276145)\n",
      "('largecar', 0.60802782)\n",
      "('car3', 0.45674708)\n",
      "('largecar', 0.57022876)\n",
      "('largecar', 0.55687338)\n",
      "('car3', 0.33033484)\n",
      "('largecar', 0.47366831)\n",
      "('car3', 0.68202376)\n",
      "('fedex', 0.8439424)\n",
      "('car3', 0.38129869)\n",
      "('car3', 0.44279402)\n",
      "('largecar', 0.52103287)\n",
      "('fedex', 0.66505975)\n",
      "('car3', 0.46955419)\n",
      "('junk', 0.99450314)\n",
      "('largecar', 0.6950314)\n",
      "('largecar', 0.49593413)\n",
      "('fedex', 0.47593674)\n",
      "('largecar', 0.60324138)\n",
      "('largecar', 0.5998928)\n",
      "('largecar', 0.46547744)\n",
      "('largecar', 0.41550702)\n",
      "('car3', 0.50574714)\n",
      "('largecar', 0.27874371)\n",
      "('fedex', 0.50800914)\n",
      "('largecar', 0.49077162)\n",
      "('car3', 0.50852138)\n",
      "('car2', 0.4551726)\n",
      "('largecar', 0.55925447)\n",
      "('largecar', 0.5083698)\n",
      "('largecar', 0.28054899)\n",
      "('largecar', 0.58836102)\n",
      "('largecar', 0.51595938)\n",
      "('largecar', 0.54734731)\n",
      "('largecar', 0.53477907)\n",
      "('largecar', 0.47494948)\n",
      "('largecar', 0.41489732)\n",
      "('largecar', 0.44537419)\n",
      "('fedex', 0.88260126)\n",
      "('largecar', 0.54409826)\n",
      "('car', 0.46639255)\n",
      "('car3', 0.6732586)\n",
      "('largecar', 0.40657514)\n",
      "('bus', 0.7435776)\n",
      "('largecar', 0.46089074)\n",
      "('car3', 0.26786894)\n",
      "('largecar', 0.72247928)\n",
      "('largecar', 0.90100211)\n",
      "('car3', 0.67814344)\n",
      "('fedex', 0.66088259)\n",
      "('largecar', 0.34795064)\n",
      "('largecar', 0.55767554)\n",
      "('car3', 0.65552884)\n",
      "('bus', 0.41805279)\n",
      "('largecar', 0.32522079)\n",
      "('largecar', 0.64595389)\n",
      "('car3', 0.61049312)\n",
      "('car3', 0.82470995)\n",
      "('car3', 0.56782031)\n",
      "('largecar', 0.47983968)\n",
      "('car3', 0.70782781)\n",
      "('largecar', 0.47453061)\n",
      "('largecar', 0.67430961)\n",
      "('bus', 0.73224109)\n",
      "('car3', 0.40111268)\n",
      "('largecar', 0.53473955)\n",
      "('car2', 0.29877025)\n",
      "('car', 0.25253788)\n",
      "('largecar', 0.46780008)\n",
      "('largecar', 0.4833636)\n",
      "('largecar', 0.50864559)\n",
      "('largecar', 0.37659296)\n",
      "('largecar', 0.71319896)\n",
      "('bus', 0.67719483)\n",
      "('fedex', 0.52112567)\n",
      "('largecar', 0.79366273)\n",
      "('largecar', 0.5236634)\n",
      "('largecar', 0.48097324)\n",
      "('largecar', 0.40987247)\n",
      "('largecar', 0.54841089)\n",
      "('bus', 0.7925365)\n",
      "('largecar', 0.41272953)\n",
      "('largecar', 0.73729283)\n",
      "('car3', 0.45209363)\n",
      "('largecar', 0.3823719)\n",
      "('largecar', 0.64565492)\n",
      "('car3', 0.39506191)\n",
      "('car3', 0.75168878)\n",
      "('car', 0.31969544)\n",
      "('largecar', 0.41099605)\n",
      "('largecar', 0.40619409)\n",
      "('largecar', 0.47849452)\n",
      "('car3', 0.455843)\n",
      "('car3', 0.42410663)\n",
      "('car3', 0.31427956)\n",
      "('car3', 0.33523187)\n",
      "('largecar', 0.64286667)\n",
      "('largecar', 0.61740446)\n",
      "('largecar', 0.66886866)\n",
      "('junk', 0.97580612)\n",
      "('largecar', 0.64764583)\n",
      "('car3', 0.49307796)\n",
      "('car', 0.33102155)\n",
      "('largecar', 0.44416559)\n",
      "('largecar', 0.52551979)\n",
      "('largecar', 0.39587027)\n",
      "('largecar', 0.46335462)\n",
      "('bus', 0.86222911)\n",
      "('car3', 0.30393144)\n",
      "('bus', 0.92591321)\n",
      "('car', 0.2338143)\n",
      "('largecar', 0.42416441)\n",
      "('largecar', 0.44366404)\n",
      "('largecar', 0.48228955)\n",
      "('car3', 0.48107734)\n",
      "('junk', 0.98959202)\n",
      "('car', 0.29624152)\n",
      "('car3', 0.61278105)\n",
      "('car3', 0.70045131)\n",
      "('largecar', 0.43350312)\n",
      "('largecar', 0.40507787)\n",
      "('car3', 0.6757015)\n",
      "('largecar', 0.72223842)\n",
      "('largecar', 0.77003175)\n",
      "('largecar', 0.43933031)\n",
      "('largecar', 0.56295002)\n",
      "('car3', 0.4918437)\n",
      "('car3', 0.44158223)\n",
      "('fedex', 0.77294785)\n",
      "('largecar', 0.49045989)\n",
      "('car3', 0.50193352)\n",
      "('largecar', 0.75655186)\n",
      "('largecar', 0.63594455)\n",
      "('largecar', 0.61442375)\n",
      "('junk', 0.99102646)\n",
      "('fedex', 0.6355865)\n",
      "('largecar', 0.63391268)\n",
      "('largecar', 0.41061309)\n",
      "('fedex', 0.79638851)\n",
      "('largecar', 0.5472095)\n",
      "('largecar', 0.41976869)\n",
      "('bus', 0.47932389)\n",
      "('car3', 0.55047697)\n",
      "('largecar', 0.43666396)\n",
      "('largecar', 0.66325903)\n",
      "('largecar', 0.76552826)\n",
      "('largecar', 0.57306921)\n",
      "('car3', 0.52237082)\n",
      "('bus', 0.87372357)\n",
      "('largecar', 0.57703149)\n",
      "('largecar', 0.49011382)\n",
      "('largecar', 0.48653844)\n",
      "('car3', 0.64841086)\n",
      "('fedex', 0.95944226)\n",
      "('largecar', 0.48487785)\n",
      "('bus', 0.66367662)\n",
      "('car3', 0.40601182)\n",
      "('largecar', 0.5464462)\n",
      "('largecar', 0.39649177)\n",
      "('largecar', 0.58243531)\n",
      "('fedex', 0.7825821)\n",
      "('largecar', 0.560646)\n",
      "('car3', 0.42537031)\n",
      "('largecar', 0.59685373)\n",
      "('largecar', 0.34720415)\n",
      "('fedex', 0.47593588)\n",
      "('largecar', 0.56442678)\n",
      "('car3', 0.61908567)\n",
      "('largecar', 0.55689639)\n",
      "('junk', 0.98646855)\n",
      "('largecar', 0.40527174)\n",
      "('car3', 0.38161469)\n"
     ]
    }
   ],
   "source": [
    "restart_df = False\n",
    "\n",
    "# run from python\n",
    "import scripts.label_image\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import time\n",
    "import psutil\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_graph(model_file):\n",
    "  graph = tf.Graph()\n",
    "  graph_def = tf.GraphDef()\n",
    "  with open(model_file, \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "  with graph.as_default():\n",
    "    tf.import_graph_def(graph_def)\n",
    "  return graph\n",
    "\n",
    "\n",
    "def read_tensor_from_image_file(file_name, input_height=299, input_width=299,\n",
    "\t\t\t\tinput_mean=0, input_std=255):\n",
    "  input_name = \"file_reader\"\n",
    "  output_name = \"normalized\"\n",
    "  file_reader = tf.read_file(file_name, input_name)\n",
    "  if file_name.endswith(\".png\"):\n",
    "    image_reader = tf.image.decode_png(file_reader, channels = 3,\n",
    "                                       name='png_reader')\n",
    "  elif file_name.endswith(\".gif\"):\n",
    "    image_reader = tf.squeeze(tf.image.decode_gif(file_reader,\n",
    "                                                  name='gif_reader'))\n",
    "  elif file_name.endswith(\".bmp\"):\n",
    "    image_reader = tf.image.decode_bmp(file_reader, name='bmp_reader')\n",
    "  else:\n",
    "    image_reader = tf.image.decode_jpeg(file_reader, channels = 3,\n",
    "                                        name='jpeg_reader')\n",
    "  float_caster = tf.cast(image_reader, tf.float32)\n",
    "  dims_expander = tf.expand_dims(float_caster, 0);\n",
    "  resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "  normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "  sess = tf.Session()\n",
    "  result = sess.run(normalized)\n",
    "  return result\n",
    "\n",
    "def load_labels(label_file):\n",
    "  label = []\n",
    "  proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "  for l in proto_as_ascii_lines:\n",
    "    label.append(l.rstrip())\n",
    "  return label\n",
    "\n",
    "\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "input_mean = 128\n",
    "input_std = 128\n",
    "input_layer = \"input\"\n",
    "output_layer = \"final_result\"\n",
    "label_file = r'/home/mmann1123/Documents/PiCameraClassifier/tf_files/retrained_labels_mobilenet_1.0_224.txt'\n",
    "model_file = r'/home/mmann1123/Documents/PiCameraClassifier/tf_files/retrained_graph_mobilenet_1.0_224.pb'\n",
    " \n",
    "\n",
    "###############################\n",
    "# iterate across series of photos \n",
    "os.chdir(r'/home/mmann1123/Dropbox/Apps/PiCameraLogger/')\n",
    "rootdir = os.getcwd()\n",
    "\n",
    "# set up storage for classifications or load existing csv of classifications\n",
    "if restart_df == True: \n",
    "    df = pd.DataFrame(columns=['Path','Date','Class','Prob'])\n",
    "else:\n",
    "    df = pd.read_csv('/home/mmann1123/Documents/PiCameraClassifier/predicted_labels.csv', index_col=0)\n",
    "\n",
    "for dir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if file == '.dropbox' or file =='predicted_labels.csv'or len(df[df['Path'].str.contains(file)])>0:\n",
    "            print(file + ' already exists in df')\n",
    "            continue\n",
    "        file_name = os.path.join(dir, file)\n",
    "        graph = load_graph(model_file)\n",
    "        t = read_tensor_from_image_file(file_name,input_height=input_height,input_width=input_width,input_mean=input_mean,input_std=input_std)\n",
    "        input_name = \"import/\" + input_layer\n",
    "        output_name = \"import/\" + output_layer\n",
    "        input_operation = graph.get_operation_by_name(input_name)\n",
    "        output_operation = graph.get_operation_by_name(output_name)\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            results = sess.run(output_operation.outputs[0],\n",
    "                  {input_operation.outputs[0]: t})\n",
    "        results = np.squeeze(results)\n",
    "        top_k = results.argsort()[-5:][::-1]\n",
    "        labels = load_labels(label_file)\n",
    "        image = Image.open( file_name)\n",
    "        font_type = ImageFont.truetype('/home/mmann1123/Documents/Fonts/unifont-10.0.07.ttf',25)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.text(xy =(50,50),text=labels[top_k[0]]+' '+np.array2string(results[top_k[0]]),fill=(255,255,255), font=font_type)\n",
    "        #image.show()\n",
    "        \n",
    "        #store path class date\n",
    "        file_name2 = os.path.splitext(file_name)[0]\n",
    "        date_in = file_name2.split(\"Picapture_\")[1]\n",
    "        date_time = datetime.strptime(date_in, \"%d_%m_%Y-%H:%M:%S\")\n",
    "        df = df.append({'Path': file_name, 'Date': date_time, 'Class': labels[top_k[0]], 'Prob': results[top_k[0]]}, ignore_index=True) \n",
    "        print(labels[top_k[0]], results[top_k[0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/home/mmann1123/Documents/PiCameraClassifier/')\n",
    "\n",
    "df.to_csv('./predicted_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./predicted_labels.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FedEx Truck Counts \n",
    "Here we count the number of high probability FedEx truck based on a photo every 2 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshhold = 0.75\n",
    "df.index  = df.Date\n",
    "df.sort_index(inplace=True)\n",
    "fedex = df.copy()\n",
    "fedex = fedex.assign(Count=pd.Series([0] * len(fedex['Date'])).values)\n",
    "fedex.loc[(fedex.Prob > threshhold) & (fedex.Class == 'fedex') ,'Count' ] =1\n",
    "fedex = fedex.assign(CumSum=pd.Series(fedex.Count.cumsum()  ).values)\n",
    "fedex.CumSum.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedex = fedex.assign(Day=pd.Series(fedex.index.strftime('%A')).values)\n",
    "fedex[['Day', 'Count']].groupby('Day').sum().plot(kind='bar', legend=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedex = fedex.assign(Hour=pd.Series(fedex.index.strftime('%H')).values)\n",
    "fedex[['Hour', 'Count']].groupby('Hour').sum().plot(kind='bar', legend=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedex.head(500)\n",
    "fedex = fedex.assign(Ones=pd.Series([1] * len(fedex['Date'])).values)\n",
    "image_h_count = fedex[['Hour', 'Ones']].groupby('Hour').sum()#.plot(kind='bar', legend=None)\n",
    "fedex_h_count = fedex[['Hour', 'Count']].groupby('Hour').sum()\n",
    "result = pd.concat([fedex_h_count, image_h_count], axis=1, join='inner')\n",
    "result['p_fedex_image'] = result.Count / result.Ones * 100\n",
    "result.p_fedex_image.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bus Counts \n",
    "Here we count the number of high probability Buses based on a photo every 2 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index  = df.Date\n",
    "df.sort_index(inplace=True)\n",
    "bus = df.copy()\n",
    "bus = bus.assign(Count=pd.Series([0] * len(bus['Date'])).values)\n",
    "bus.loc[(bus.Prob > threshhold) & (bus.Class == 'bus') ,'Count' ] =1\n",
    "bus = bus.assign(CumSum=pd.Series(bus.Count.cumsum()  ).values)\n",
    "bus.CumSum.plot()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = bus.assign(Day=pd.Series(bus.index.strftime('%A')).values)\n",
    "bus[['Day', 'Count']].groupby('Day').sum().plot(kind='bar', legend=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = bus.assign(Hour=pd.Series(bus.index.strftime('%H')).values)\n",
    "bus[['Hour', 'Count']].groupby('Hour').sum().plot(kind='bar', legend=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
